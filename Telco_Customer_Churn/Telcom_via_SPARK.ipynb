{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recent-essex",
   "metadata": {},
   "source": [
    "see also https://www.youtube.com/watch?v=hbTJvjfX1fA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incoming-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sublime-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "portuguese-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, QuantileDiscretizer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "asian-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blessed-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setAppName(\"Telcom\").setMaster(\"local[4]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consecutive-clarity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://h2894565.stratoserver.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Telcom</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[4] appName=Telcom>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "neutral-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('./data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df = sqlContext.read.format('csv').options(header='true', inferschema='true').load('./data/WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dominican-round",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|7590-VHVEG|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|         29.85|       29.85|   No|\n",
      "|5575-GNVDE|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|        Mailed check|         56.95|      1889.5|   No|\n",
      "|3668-QPYBK|  Male|            0|     No|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|        Mailed check|         53.85|      108.15|  Yes|\n",
      "|7795-CFOCW|  Male|            0|     No|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|Bank transfer (au...|          42.3|     1840.75|   No|\n",
      "|9237-HQITU|Female|            0|     No|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|          70.7|      151.65|  Yes|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "several-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- SeniorCitizen: integer (nullable = true)\n",
      " |-- Partner: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- PhoneService: string (nullable = true)\n",
      " |-- MultipleLines: string (nullable = true)\n",
      " |-- InternetService: string (nullable = true)\n",
      " |-- OnlineSecurity: string (nullable = true)\n",
      " |-- OnlineBackup: string (nullable = true)\n",
      " |-- DeviceProtection: string (nullable = true)\n",
      " |-- TechSupport: string (nullable = true)\n",
      " |-- StreamingTV: string (nullable = true)\n",
      " |-- StreamingMovies: string (nullable = true)\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- PaperlessBilling: string (nullable = true)\n",
      " |-- PaymentMethod: string (nullable = true)\n",
      " |-- MonthlyCharges: double (nullable = true)\n",
      " |-- TotalCharges: string (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "australian-rating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
      "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|Contract|PaperlessBilling|PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
      "+----------+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
      "|         0|     0|            0|      0|         0|     0|           0|            0|              0|             0|           0|               0|          0|          0|              0|       0|               0|            0|             0|           0|    0|\n",
      "+----------+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([F.count(F.when(F.col(c).isNull() | F.isnan(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-painting",
   "metadata": {},
   "source": [
    "# Process with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-painting",
   "metadata": {},
   "source": [
    "### PySpark -- Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Churn').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-vocabulary",
   "metadata": {},
   "source": [
    "* imbalanced groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('tenure','TotalCharges','MonthlyCharges').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "regulated-bookmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+\n",
      "|churn|Female|Male|\n",
      "+-----+------+----+\n",
      "|   No|  2549|2625|\n",
      "|  Yes|   939| 930|\n",
      "+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('churn').pivot('gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "exact-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+----+\n",
      "|SeniorCitizen|  No| Yes|\n",
      "+-------------+----+----+\n",
      "|            1| 666| 476|\n",
      "|            0|4508|1393|\n",
      "+-------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('SeniorCitizen').pivot('churn').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "beginning-hayes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levels of \"churn\": ['No', 'Yes']\n",
      "+-------------+------------------+-------------------+\n",
      "|SeniorCitizen|                No|                Yes|\n",
      "+-------------+------------------+-------------------+\n",
      "|            1|0.5831873905429071| 0.4168126094570928|\n",
      "|            0| 0.763938315539739|0.23606168446026096|\n",
      "+-------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_normalized_pivot(df, group_col, pivot_col, verbose=1):\n",
    "    \n",
    "    # https://stackoverflow.com/questions/40805808/percentage-count-per-group-and-pivot-with-pyspark\n",
    "    levels = [x for x in chain(*df.select(\"churn\").distinct().collect())]\n",
    "    if verbose: print(f'levels of \"{pivot_col}\": {levels}')\n",
    "    \n",
    "    pivoted = df.groupby(group_col).pivot(pivot_col, levels).count()\n",
    "    row_count = sum(F.coalesce(F.col(x), F.lit(0)) for x in levels)\n",
    "    #row_count = sum(coalesce(col(x), lit(0)) for x in levels)\n",
    "    adjusted = [(F.col(x) / row_count).alias(x) for x in levels]\n",
    "    return pivoted.select(F.col(group_col), *adjusted)\n",
    "                    \n",
    "make_normalized_pivot(df=df, group_col='SeniorCitizen', pivot_col='churn').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "decent-backup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+----+-----------+----+\n",
      "|SeniorCitizen_InternetService| DSL|Fiber optic|  No|\n",
      "+-----------------------------+----+-----------+----+\n",
      "|                            1| 259|        831|  52|\n",
      "|                            0|2162|       2265|1474|\n",
      "+-----------------------------+----+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.stat.crosstab(\"SeniorCitizen\",\"InternetService\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "advisory-frederick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|SeniorCitizen|InternetService|\n",
      "+-------------+---------------+\n",
      "|            0|             No|\n",
      "|            1|            DSL|\n",
      "|            1|    Fiber optic|\n",
      "|            0|            DSL|\n",
      "|            0|            DSL|\n",
      "|            0|             No|\n",
      "|            0|            DSL|\n",
      "|            0|            DSL|\n",
      "|            0|             No|\n",
      "|            0|    Fiber optic|\n",
      "|            1|    Fiber optic|\n",
      "|            0|             No|\n",
      "|            1|    Fiber optic|\n",
      "|            1|    Fiber optic|\n",
      "|            0|    Fiber optic|\n",
      "|            1|    Fiber optic|\n",
      "|            0|             No|\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('SeniorCitizen','InternetService').sample(False,.002).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-steal",
   "metadata": {},
   "source": [
    "### PySpark -- Mach Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "organic-discipline",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`customerID`' given input columns: [Churn, Contract, Dependents, DeviceProtection, InternetService, MonthlyCharges, MultipleLines, OnlineBackup, OnlineSecurity, PaperlessBilling, Partner, PaymentMethod, PhoneService, SeniorCitizen, StreamingMovies, StreamingTV, TechSupport, TotalCharges, gender, tenure];\n'Project ['customerID]\n+- Project [gender#472, SeniorCitizen#473, Partner#474, Dependents#475, tenure#476, PhoneService#477, MultipleLines#478, InternetService#479, OnlineSecurity#480, OnlineBackup#481, DeviceProtection#482, TechSupport#483, StreamingTV#484, StreamingMovies#485, Contract#486, PaperlessBilling#487, PaymentMethod#488, MonthlyCharges#489, TotalCharges#490, Churn#491]\n   +- Relation[customerID#471,gender#472,SeniorCitizen#473,Partner#474,Dependents#475,tenure#476,PhoneService#477,MultipleLines#478,InternetService#479,OnlineSecurity#480,OnlineBackup#481,DeviceProtection#482,TechSupport#483,StreamingTV#484,StreamingMovies#485,Contract#486,PaperlessBilling#487,PaymentMethod#488,MonthlyCharges#489,TotalCharges#490,Churn#491] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-3b71702319ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Will drop customerID -- but first save it to a vector or later reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcustomerID_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'customerID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcustomerID_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# DROP:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \"\"\"\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`customerID`' given input columns: [Churn, Contract, Dependents, DeviceProtection, InternetService, MonthlyCharges, MultipleLines, OnlineBackup, OnlineSecurity, PaperlessBilling, Partner, PaymentMethod, PhoneService, SeniorCitizen, StreamingMovies, StreamingTV, TechSupport, TotalCharges, gender, tenure];\n'Project ['customerID]\n+- Project [gender#472, SeniorCitizen#473, Partner#474, Dependents#475, tenure#476, PhoneService#477, MultipleLines#478, InternetService#479, OnlineSecurity#480, OnlineBackup#481, DeviceProtection#482, TechSupport#483, StreamingTV#484, StreamingMovies#485, Contract#486, PaperlessBilling#487, PaymentMethod#488, MonthlyCharges#489, TotalCharges#490, Churn#491]\n   +- Relation[customerID#471,gender#472,SeniorCitizen#473,Partner#474,Dependents#475,tenure#476,PhoneService#477,MultipleLines#478,InternetService#479,OnlineSecurity#480,OnlineBackup#481,DeviceProtection#482,TechSupport#483,StreamingTV#484,StreamingMovies#485,Contract#486,PaperlessBilling#487,PaymentMethod#488,MonthlyCharges#489,TotalCharges#490,Churn#491] csv\n"
     ]
    }
   ],
   "source": [
    "# Will drop customerID -- but first save it to a vector or later reference\n",
    "customerID_vec = df.select('customerID')\n",
    "customerID_vec.show(2)\n",
    "\n",
    "# DROP:\n",
    "df = df.drop('customerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "manufactured-oakland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900 2143\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = df.randomSplit([.7,.3], seed=0)\n",
    "print(train_data.count(), test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-abuse",
   "metadata": {},
   "source": [
    "#### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "noticed-terror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender_Indexed',\n",
       " 'Partner_Indexed',\n",
       " 'Dependents_Indexed',\n",
       " 'PhoneService_Indexed',\n",
       " 'MultipleLines_Indexed',\n",
       " 'InternetService_Indexed',\n",
       " 'OnlineSecurity_Indexed',\n",
       " 'OnlineBackup_Indexed',\n",
       " 'DeviceProtection_Indexed',\n",
       " 'TechSupport_Indexed',\n",
       " 'StreamingTV_Indexed',\n",
       " 'StreamingMovies_Indexed',\n",
       " 'Contract_Indexed',\n",
       " 'PaperlessBilling_Indexed',\n",
       " 'PaymentMethod_Indexed',\n",
       " 'TotalCharges_Indexed',\n",
       " 'Churn_Indexed',\n",
       " 'SeniorCitizen_Indexed']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c + '_Indexed' for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "copyrighted-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = ['Churn']\n",
    "ytrue = [c + '_Indexed' for c in ytrue_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "through-forestry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SeniorCitizen', 'tenure', 'MonthlyCharges']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = [name for name, dtype in df.dtypes if dtype in ('int','float','double')]\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "popular-balloon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'Partner',\n",
       " 'Dependents',\n",
       " 'PhoneService',\n",
       " 'MultipleLines',\n",
       " 'InternetService',\n",
       " 'OnlineSecurity',\n",
       " 'OnlineBackup',\n",
       " 'DeviceProtection',\n",
       " 'TechSupport',\n",
       " 'StreamingTV',\n",
       " 'StreamingMovies',\n",
       " 'Contract',\n",
       " 'PaperlessBilling',\n",
       " 'PaymentMethod',\n",
       " 'TotalCharges']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_cols = [name for name, dtype in df.dtypes if dtype=='string' and name not in ytrue_cols]\n",
    "str_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "choice-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = ['SeniorCitizen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "elect-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = str_cols + bin_cols\n",
    "cat_cols_inds = [c + '_Indexed' for c in cat_cols]\n",
    "cat_cols_ohes = [c + '_OHE' for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "electrical-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "SI = StringIndexer()\n",
    "SI.setInputCols(cat_cols)\n",
    "SI.setOutputCols(cat_cols_inds)\n",
    "\n",
    "OHE = OneHotEncoder()\n",
    "OHE.setInputCols(cat_cols_inds)\n",
    "OHE.setOutputCols(cat_cols_ohes)\n",
    "OHE\n",
    "\n",
    "LE = StringIndexer(inputCols=ytrue_cols, outputCols=label_cols_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "apparent-nicaragua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantileDiscretizer_399921314240"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QD = QuantileDiscretizer(numBuckets=3, inputCols=['tenure'], outputCols=['tenure_bined'])\n",
    "QD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-doctor",
   "metadata": {},
   "source": [
    "#### transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dietary-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "VA = VectorAssembler(inputCols=cat_cols_ohes + num_cols, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "charitable-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = [SI, OHE, LE, QD, VA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "impressed-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit() and transform() are applied on different objects ....\n",
    "feature_pipeline = Pipeline().setStages(stages)\n",
    "feature_pipelineModel = feature_pipeline.fit(train_data)\n",
    "\n",
    "train_data_transformed = feature_pipelineModel.transform(train_data)\n",
    "test_data_transformed = feature_pipelineModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "defined-murray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Row(tenure_bined=0.0), Row(tenure_bined=0.0), Row(tenure_bined=0.0), Row(tenure_bined=0.0), Row(tenure_bined=2.0)]'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(train_data_transformed.select('tenure_bined').sample(fraction=.1).head(5))#.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "intensive-prison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(4659, {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 5: 1.0, 7: 1.0, 8: 1.0, 10: 1.0, 12: 1.0, 14: 1.0, 16: 1.0, 19: 1.0, 20: 1.0, 24: 1.0, 3247: 1.0, 4655: 1.0, 4657: 9.0, 4658: 59.9}))]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_transformed.select('features').head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-emerald",
   "metadata": {},
   "source": [
    "#### Classification: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "buried-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(labelCol=label_cols_le[0], featuresCol=\"features\")\n",
    "lr_clf = lr_clf.fit(train_data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "strong-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'rawPrediction'>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.transform(test_data_transformed.select('features')).rawPrediction#.select('prediction').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "biological-oxford",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "label does not exist. Available: customerID, gender, SeniorCitizen, Partner, Dependents, tenure, PhoneService, MultipleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, Contract, PaperlessBilling, PaymentMethod, MonthlyCharges, TotalCharges, Churn, Contract_Indexed, DeviceProtection_Indexed, OnlineBackup_Indexed, OnlineSecurity_Indexed, SeniorCitizen_Indexed, MultipleLines_Indexed, Partner_Indexed, gender_Indexed, PhoneService_Indexed, PaperlessBilling_Indexed, PaymentMethod_Indexed, Dependents_Indexed, InternetService_Indexed, TechSupport_Indexed, StreamingMovies_Indexed, StreamingTV_Indexed, TotalCharges_Indexed, PhoneService_OHE, OnlineSecurity_OHE, Contract_OHE, SeniorCitizen_OHE, PaperlessBilling_OHE, TotalCharges_OHE, Dependents_OHE, TechSupport_OHE, StreamingTV_OHE, MultipleLines_OHE, InternetService_OHE, PaymentMethod_OHE, OnlineBackup_OHE, StreamingMovies_OHE, gender_OHE, DeviceProtection_OHE, Partner_OHE, Churn_Indexed, tenure_bined, features, rawPrediction, probability, prediction",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-0eeb2e46c382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mBCE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawPredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: label does not exist. Available: customerID, gender, SeniorCitizen, Partner, Dependents, tenure, PhoneService, MultipleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, Contract, PaperlessBilling, PaymentMethod, MonthlyCharges, TotalCharges, Churn, Contract_Indexed, DeviceProtection_Indexed, OnlineBackup_Indexed, OnlineSecurity_Indexed, SeniorCitizen_Indexed, MultipleLines_Indexed, Partner_Indexed, gender_Indexed, PhoneService_Indexed, PaperlessBilling_Indexed, PaymentMethod_Indexed, Dependents_Indexed, InternetService_Indexed, TechSupport_Indexed, StreamingMovies_Indexed, StreamingTV_Indexed, TotalCharges_Indexed, PhoneService_OHE, OnlineSecurity_OHE, Contract_OHE, SeniorCitizen_OHE, PaperlessBilling_OHE, TotalCharges_OHE, Dependents_OHE, TechSupport_OHE, StreamingTV_OHE, MultipleLines_OHE, InternetService_OHE, PaymentMethod_OHE, OnlineBackup_OHE, StreamingMovies_OHE, gender_OHE, DeviceProtection_OHE, Partner_OHE, Churn_Indexed, tenure_bined, features, rawPrediction, probability, prediction"
     ]
    }
   ],
   "source": [
    "y_pred = lr_clf.transform(test_data_transformed)\n",
    "BCE = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "AUC = BCE.evaluate(y_pred)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-complaint",
   "metadata": {},
   "source": [
    "# Process as standard pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "endangered-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = df.sample(False, .05, seed=1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "south-advancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-rebecca",
   "metadata": {},
   "source": [
    "# Process as SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dependent-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_table_name = \"churn_analysis\"\n",
    "df.createOrReplaceTempView(tmp_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "extraordinary-payday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "vanilla-accreditation",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-a45a80323020>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-a45a80323020>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    select * from churn_analysis\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%sql\n",
    "select * from churn_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-petite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
